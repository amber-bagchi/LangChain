from langchain_huggingface import HuggingFaceEndpointEmbeddings
from dotenv import load_dotenv
import os
import sys

# 1Ô∏è‚É£ Load variables from .env
load_dotenv()

# 2Ô∏è‚É£ Get token
token = os.getenv("HUGGINGFACEHUB_ACCESS_TOKEN")
if not token:
    print("‚ùå ERROR: Hugging Face API token not found.")
    sys.exit(1)
else:
    print("‚úÖ Hugging Face token loaded successfully.")

# 3Ô∏è‚É£ Initialize API-based embeddings
embedding = HuggingFaceEndpointEmbeddings(
    model="sentence-transformers/all-MiniLM-L6-v2",  # you can switch to other models
    huggingfacehub_api_token=token
)

# 4Ô∏è‚É£ Example documents
docs = [
    "This is a sentence",
    "This is another sentence",
    "This is a third"
]

# 5Ô∏è‚É£ Generate embeddings
try:
    embeddings = embedding.embed_documents(docs)
    print("‚úÖ Embeddings generated successfully\n")

    for i, emb in enumerate(embeddings):
        print(f"üîπ Document {i+1}: {docs[i]}")
        print(f"   Vector length: {len(emb)}")
        print(f"   First 10 values: {emb[:10]} ...\n")  # show first 10 values only
except Exception as e:
    print("‚ùå ERROR during embedding generation:", e)
